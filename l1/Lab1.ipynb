{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "natural-royalty",
   "metadata": {},
   "source": [
    "# Lab 1: Basic Data Analysis\n",
    "\n",
    "The purpose of this lab is to get you started running Jupyter notebooks and familiar loading and analyzing data in a notebook. In particular, we will explore the basics of NumPy and Pandas by exploring of some public policy datasets from the Chicago Data Portal. Some of the examples below are adapted from *Machine Learning with Python Cookbook* by Chris Albon.\n",
    "\n",
    "Parts 0, 1 & 2 involve running provided code to become familiar with the libraries. Don't rush through these parts because the code already works. Instead, make sure you understand what is happening and how to replicate it if you were given similar data without the provided code. Part 3 involves writing your own code to explore a new dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-metabolism",
   "metadata": {},
   "source": [
    "# 0. Jupyter Notebooks\n",
    "\n",
    "Elements in a notebook are divided into cells, which might be markdown text (such as this cell) or code (such as the next cell). You can execute either type of cell by clicking on it and typing \"Shift + Enter\". Execute the following cell to run the \"Hello World\" program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello, World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-sodium",
   "metadata": {},
   "source": [
    "You can also define functions and variables in cells. Once you have run the cell, the functions and variables are available to any cell in the notebook, *even cells above where the variables or functions were defined.* This can be a source of bugs if you start running cells out of order and forget that a later cell overwrote a function or variable value. If you want to reset Python and remove all defined values, use the Kernel > Restart Kernel option from the menu bar. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-business",
   "metadata": {},
   "source": [
    "## 1. Numpy\n",
    "\n",
    "\n",
    "NumPy is the foundation of the Python machine learning stack. It allows for efficient operations on the data structures often used in machine learning: vectors, arrays, and matrices.\n",
    "\n",
    "This section covers the most common NumPy operations you are likely to run into when preparing data for ML\n",
    "\n",
    "* 1.1 Creating a Vector\n",
    "* 1.2 Creating an Array\n",
    "* 1.3 Cereating a Sparse Matrix\n",
    "* 1.4 Selecting Elements in an Array\n",
    "* 1.5 Describing an Array\n",
    "* 1.6 Applying Operations to Elements\n",
    "* 1.7 Calculating Basic Statistics\n",
    "* 1.8 Reshaping Arrays\n",
    "* 1.9 Other Array Operations\n",
    "\n",
    "\n",
    "#### 1.1 Creating a Vector\n",
    "\n",
    "Use NumPy's built in array type to create a one-dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import numpy as np\n",
    "\n",
    "# create a row vector\n",
    "vector_row = np.array([1, 2, 3])\n",
    "\n",
    "# create a column vector\n",
    "vector_column = np.array([[1],\n",
    "                          [2],\n",
    "                          [3]])\n",
    "\n",
    "# display\n",
    "print(vector_row)\n",
    "print(vector_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-coaching",
   "metadata": {},
   "source": [
    "### 1.2 Creating an Array or Matrix\n",
    "\n",
    "To create a 2D or higher dimensional array,  we can also use a NumPy's array type. In the code below, the array (matrix) contains three rows and two columns (a column of 1s and a column of 2s)\n",
    "\n",
    "NumPy also has a builtin \"matrix\" data type separate from `array`, however the matrix data type is not recommended for two reasons. First, `array` is the de facto standard data structure of NumPy. Second the vast majority of NumPy operations return arrays, not matrix objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix\n",
    "matrix = np.array([[1, 2],\n",
    "                   [1, 2],\n",
    "                   [1, 2]])\n",
    "\n",
    "# display\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-array",
   "metadata": {},
   "source": [
    "### 1.3 Creating a Sparse Matrix\n",
    "Sparse matrices allow you to efficiently represent data with very few nonzero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from scipy import sparse\n",
    "\n",
    "# create a matrix\n",
    "matrix = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [3, 0]])\n",
    "\n",
    "# create compressed sparse row (CSR) matrix\n",
    "matrix_sparse = sparse.csr_matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-frame",
   "metadata": {},
   "source": [
    "A frequent situation in machine learning occurs when you have a huge amount of data but most of the elements in the data are zeros. For example, imagine a matrix where the columns are every movie on Netflix, the rows are every Netflix user, and the values are how many times a user has watched that particular movie. This matrix would have tens of thousands of columns and millions of rows. However, since most users do not watch most movies, the vast majority of elements would be zero.\n",
    "\n",
    "Sparse matrices only store nonzero elements and assume all other values will be zero, leading to significant computational savings. In the above code, we created a NumPy array with two nonzero values, then converted it into a sparse matrix. If we view the sparse matrix we can see that only the nonzero values are stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view sparse matrix\n",
    "print(matrix_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-hearing",
   "metadata": {},
   "source": [
    "There are a number of ways to represent sparse matrices. However, in compressed sparse row (CSR) matrices, (1, 1) and (2, 0) represent the (zero-indexed) indices of the non-zero values 1 and 3, respectively. For example, the element 1 is in the second row and second column. We can see the advantage of sparse matrices if we create a much larger matrix with many more zero elements and then compare this larger matrix with our original sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create larger matrix\n",
    "matrix_large = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                         [3, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# create compressed sparse row (CSR) matrix\n",
    "matrix_large_sparse = sparse.csr_matrix(matrix_large)\n",
    "\n",
    "# view larger sparse matrix\n",
    "print(matrix_large_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view original sparse matrix\n",
    "print(matrix_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-wichita",
   "metadata": {},
   "source": [
    "Despite the fact that we added many more zero elements in the larger matrix, its sparse representation is exactly the same as our original sparse matrix. \n",
    "\n",
    "#### See Also\n",
    "* Sparse matrices, SciPy documentation (https://docs.scipy.org/doc/scipy/reference/sparse.html)\n",
    "* 101 Ways to Store a Sparse Matrix (https://medium.com/@jmaxg3/101-ways-to-store-a-sparse-matrix-c7f2bf15a229)\n",
    "\n",
    "### 1.4 Selecting Elements in an Array\n",
    "You often need to select one or more elements in a vector or array. Fortunately, NumPy arrays make that easy. Like most things in Python, NumPy arrays are zero-indexed, meaning that the index of the first element is 0, not 1. With that caveat, NumPy offers a wide variety of methods for selecting (i.e., indexing and slicing) elements or groups of elements in arrays. Some examples are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create row vector\n",
    "vector = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# create array\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "# select the third element of vector\n",
    "vector[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select second row, second column of array\n",
    "matrix[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all elements of vector\n",
    "vector[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select everything up to and including the third element of vector\n",
    "vector[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the last element of vector\n",
    "vector[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first two rows and all columns of array\n",
    "matrix[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all rows and the second column of array\n",
    "matrix[:,1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-cheat",
   "metadata": {},
   "source": [
    "These techniques generalize beyond 2D arrays to arbitrary dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-counter",
   "metadata": {},
   "source": [
    "### 1.5 Describing an Array\n",
    "\n",
    "If it often helpful to be able to describe the shape, size, and dimensions of a NumPy array. The shape, size, and ndim functions allow you to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array\n",
    "matrix = np.array([[1, 2, 3, 4],\n",
    "                   [5, 6, 7, 8],\n",
    "                   [9, 10, 11, 12]])\n",
    "\n",
    "# view number of rows and columns\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view number of elements (rows * columns)\n",
    "matrix.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view number of dimensions\n",
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-mirror",
   "metadata": {},
   "source": [
    "Although this might seem basic, it is frequently valuable to check the shape and size of an array before further calculations (e.g. to make sure it is the right shape for input into a ML algorithm) or simply as a gut check after performing an operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-shopping",
   "metadata": {},
   "source": [
    "### 1.6 Applying Operations to Elements\n",
    "Some data preprocessing operations involve applying a function to multiple elements in an array. This is easy using NumPy's vectorize() function, which behaves much like the Python map() function only it uses the broadcasting rules of NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "# create function that adds 1000 to something\n",
    "add_1000 = lambda i: i + 1000\n",
    "\n",
    "# create vectorized function\n",
    "vectorized_add_1000 = np.vectorize(add_1000)\n",
    "\n",
    "# apply function to all elementsin matrix\n",
    "vectorized_add_1000(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-consultation",
   "metadata": {},
   "source": [
    "Vectorize converts an argument function into a new function that can apply to all elements in an array or slice of an array. It’s worth noting that vectorize() is essentially a for loop over the elements and does not increase performance. Furthermore, NumPy arrays allow us to perform operations between arrays even if their dimensions are not the same (a process called broadcasting). For example, we can create a much simpler version of our solution using broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 1000 to all elements\n",
    "matrix + 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-invalid",
   "metadata": {},
   "source": [
    "Broadcasting makes performing operations that combine arrays and constants very concise. A common preprocessing operation involves adding 1 to arrays with very small values to avoid doing math on small fractions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-study",
   "metadata": {},
   "source": [
    "### 1.7 Calculating Basic Statistics\n",
    "\n",
    "NumPy also provides functions for computing basic statistics about data arrays. It is often helpful to inspect these statistics before ML training to better understand your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "# find maximum element\n",
    "np.max(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find minimum element\n",
    "np.min(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find maximum element in each column\n",
    "np.max(matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find maximum element in each row\n",
    "np.max(matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find mean across entire matrix\n",
    "np.mean(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find variance across entire matrix\n",
    "np.var(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find standard deviation across entire matrix\n",
    "np.std(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-concert",
   "metadata": {},
   "source": [
    "Just like with max and min, we can easily get descriptive statistics about the whole matrix or just do calculations along a single axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean value in each column\n",
    "np.mean(matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean value in each row\n",
    "np.mean(matrix, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-archive",
   "metadata": {},
   "source": [
    "### 1.8 Reshaping Arrays\n",
    "\n",
    "Machine learning algorithms often expect input data in a particular shape or dimensionality. NumPy makes it easy to change the shape (number of rows and columns) of an array without changing the element values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 4x3 matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9],\n",
    "                   [10, 11, 12]])\n",
    "\n",
    "# reshape matrix into 2x6 matrix\n",
    "matrix.reshape(2, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-institution",
   "metadata": {},
   "source": [
    "The reshape() function allows us to restructure an array so that we maintain the same data but it is organized as a different number of rows and columns. The only requirement is that the shape of the original and new matrix contain the same number of elements (i.e., the same size). We can see the size of a matrix using size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-documentation",
   "metadata": {},
   "source": [
    "One useful argument to reshape is -1, which effectively means “as many as needed,” so reshape(-1, 1) means one row and as many columns as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-malaysia",
   "metadata": {},
   "source": [
    "Finally, if we provide one integer, reshape will return a 1D array of that length. The flatten() function will also do the same thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.reshape(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-encounter",
   "metadata": {},
   "source": [
    "Occasionally, you may want to transpose a vector or matrix. Transposing is a common operation in linear algebra where the column and row indices of each element are swapped. Transposition is performed in NumPy using the T field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-transition",
   "metadata": {},
   "source": [
    "One nuanced point is that, technically, a vector cannot be transposed because it is just a collection of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose vector\n",
    "np.array([1, 2, 3, 4, 5, 6]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-bridal",
   "metadata": {},
   "source": [
    "However, it is common to refer to transposing a vector as converting a row vector (notice the second pair of brackets) to a column vector or vice versa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose row vector into column vector\n",
    "np.array([[1, 2, 3, 4, 5, 6]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-times",
   "metadata": {},
   "source": [
    "Using a row vector when you should have a column vector (or vice versa) is a common gotcha when supplying data to ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-roman",
   "metadata": {},
   "source": [
    "### 1.9 Other Array Operations\n",
    "\n",
    "NumPy provides many more built-in functions and methods for performing operations on data arrays. Descriptions are all available in the NumPy documentation. \n",
    "\n",
    "**Final recommendation:** If you are ever considering writing a loop to process a data array one element at a time, there are probably more efficient methods using array operations and array broadcasting. Stack Overflow is very helpful for finding these tricks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-savage",
   "metadata": {},
   "source": [
    "# 2. Pandas\n",
    "\n",
    "The Pandas library simplifies the import and manipulation of labeled data arrays (arrays where the rows and columns have names). \n",
    "\n",
    "This section provides examples of some common Pandas operations you are likely to run into when preparing data for ML:\n",
    "\n",
    "* 2.1 Loading (Importing) Data\n",
    "* 2.2 Basic Data Exploration\n",
    "* 2.3 Handling Time Series\n",
    "* 2.4 Plotting Data\n",
    "* 2.5 Additional Pandas Operations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-alcohol",
   "metadata": {},
   "source": [
    "### 2.1 Loading (Importing) Data\n",
    "\n",
    "Pandas lets you easily import data from CSV, Excel, and JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Example \n",
    "\n",
    "# path to CSV file (URL or path to file on your hard drive)\n",
    "path = \"https://people.sc.fsu.edu/~jburkardt/data/csv/cities.csv\"\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# view the first five rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel Example\n",
    "\n",
    "# path to Excel file (URL or path to file on your hard drive)\n",
    "path = \"https://www.sample-videos.com/xls/Sample-Spreadsheet-10-rows.xls\"\n",
    "\n",
    "# load data\n",
    "df = pd.read_excel(path, sheet_name=0, header=None)\n",
    "\n",
    "# view the first five rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-enterprise",
   "metadata": {},
   "source": [
    "### 2.2 Basic Data Exploration\n",
    "\n",
    "Now let's start to explore the cta-ridership.csv dataset from the Chicago Data Portal with information about rides on the Chicago \"L\" system. The first step is to import the data and see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cta-ridership.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-wallace",
   "metadata": {},
   "source": [
    "Immediately from looking at this, we can get an understanding of the type of data we're looking at.  There's a station identifier and name, a date on which the statistic takes place, the day type, and the number of rides for that date.\n",
    "\n",
    "It's not immediately clear what A/W, is, but looking at the description of the dataset here:\n",
    "https://data.cityofchicago.org/Transportation/CTA-Ridership-L-Station-Entries-Daily-Totals/5neh-572f\n",
    "\n",
    "tells us that this column indicates that we are looking at a weekday, weekend, or holiday.\n",
    "\n",
    "We can then explore some basic characteristics of the data, including the size of the dataset, min/max/etc. to explore outliers, etc. This basic exploration allows us to spot potential outliers and mistakes in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-corrections",
   "metadata": {},
   "source": [
    "So the data has 1028040 rows and 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-mauritius",
   "metadata": {},
   "source": [
    "We notice that there is a station with no rides (minimum is zero!). Also, the station with the maximum number of rides appears to be about 10x the mean and median. Let's have a look at what station that is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the station with the most rides. This expression takes some work to parse, so make sure you understand what's going on\n",
    "df[df['rides'] == max(df['rides'])].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-swift",
   "metadata": {},
   "source": [
    "We can also find the stations with 0 rides on particular days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find stations/day combos with 0 rides \n",
    "zero = df[df['rides'] == 0]\n",
    "\n",
    "# display 5 of them\n",
    "zero.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-aside",
   "metadata": {},
   "source": [
    "Looks like a lot of weekends and holidays.  We can group by columns and types to get a better understanding of what might be going on. We then use these groups to count how many dates a station had zero rides and sort these in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerogroups = zero.groupby(['stationname','daytype']).count()\n",
    "zerogroups.sort_values(by=['date'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-somewhere",
   "metadata": {},
   "source": [
    "It should be clear from a little bit of research why some of the stations at the top of the list report dates with 0 rides. If you're curious, do some searching to find out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-bible",
   "metadata": {},
   "source": [
    "**Note:** The groupby() function is very powerful, enabling statistics and feature extraction from combinations (groups) of data attributes. However, groupby() does not return an array directly, but a GroupBy object that must have other functions applied to it to be useful. Again, the Pandas documentation and Stack Overflow are your friends. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-raleigh",
   "metadata": {},
   "source": [
    "### 2.3 Handling Time Series\n",
    "\n",
    "Many ML problems involve identifying temporal patterns in data. Pandas makes it easy to treat columns of a dataset as dates and handle them appropriately (although some ML algorithms will require conversion into a specific time format, e.g. UNIX time)\n",
    "\n",
    "Let's continue with the CTA ridership data for this section. First, lets see what the time range is in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-johns",
   "metadata": {},
   "source": [
    "So we have all rides from January 1, 2001 to December 31, 2019. Let's do some statistics that group rides by date. First we need to tell Pandas that the date column is in fact a date. So, we convert the column to a proper 'DateTime' type, and then set the index to this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the 'date' column to a datetime object and set that column as the index of the dataset\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-wichita",
   "metadata": {},
   "source": [
    "Now the date column is the index, but the rows are not sorted chronologically. We can fix this with a sort function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the columns by date\n",
    "rides_by_date = df.sort_values(by='date')\n",
    "\n",
    "rides_by_date.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-database",
   "metadata": {},
   "source": [
    "That looks better. But it sure would be easier to visualize this data in the form of a plot..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-technician",
   "metadata": {},
   "source": [
    "### 2.4 Plotting Data\n",
    "\n",
    "Plotting data is extremely useful for understanding it's properties. We will be using a combination of the Matplotlib, Seaborn, and Pandas libraries for plotting data in this class. \n",
    "Plotting is as much an art as a science, and everything you learned in middle and high school science classes about making plots clear, nondeceptive, and well-labeled still applies here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Tell Jupyter notebooks to put the plot below the cell rather than in a separate window\n",
    "%matplotlib inline \n",
    "\n",
    "# set the size of the plot\n",
    "sns.set(rc={'figure.figsize':(11, 4)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-piece",
   "metadata": {},
   "source": [
    "The following example shows one way to plot the CTA ridership from the Garfield Green station over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rides from the Garfield Green Line station\n",
    "garfield_green = rides_by_date[rides_by_date['stationname'] == 'Garfield-South Elevated']\n",
    "\n",
    "# plot the rides using the Pandas plot method\n",
    "garfield_green['rides'].plot(linewidth=0.5)\n",
    "\n",
    "# Label the plot\n",
    "plt.ylabel(\"Rides\")\n",
    "plt.xlabel(\"Date\")\n",
    "# There are many more matplotlib functions for making plots prettier. The Matplotlib documentation has examples of their use, and we will see more in future class exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-positive",
   "metadata": {},
   "source": [
    "This indicates that something unusual may have happened near the Garfield Green Line in the early part of 2014...that or there was a problem with the data collection during that period that resulted in inflated ridership counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-hacker",
   "metadata": {},
   "source": [
    "### 2.5 Additional Pandas Operations\n",
    "Like NumPy, Pandas comes with many more builtin functions and methods for manipulating data. Descriptions are all available in the Pandas documentation, and Google searches are a good place to start if you want to know how to do something specific."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-boating",
   "metadata": {},
   "source": [
    "# Part 3. Try It Yourself\n",
    "\n",
    "In this section, you will try writing your own code to analyze data about Divvy bike sharing trips in Chicago - one of the many public datasets from the Chicago Data Portal.\n",
    "\n",
    "The first step is to download the [Divvy Trip data](https://data.cityofchicago.org/Transportation/Divvy-Trips/fg6s-gzvg) as a CSV file and import it into a Pandas data frame.\n",
    "\n",
    "**Note**: The file is large (5 GB), and so this will possibly take a fair bit of time to download/load. Be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-devil",
   "metadata": {},
   "source": [
    "### 3.1 Basic Data Analysis\n",
    "Now that you have the data loaded into a dataframe, you can write code to answer the following questions about the data using Pandas. Your code should print the answer to the questions with as little extra \"fluff\" as possible\n",
    "\n",
    "#### 3.1.1 What is the number of rows in the data frame? \n",
    "\n",
    "This question is intended to help you understand one of the most basic questions about your data: How many data points does it have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-casting",
   "metadata": {},
   "source": [
    "#### 3.1.2 What are the start and end dates of the rides in the data set?\n",
    "\n",
    "It is typically important to understand basic information about the data, such as when it starts and ends.  This is also an example of _looking for outliers_. The Divvy program started in Chicago somewhat recently (find out when!) and so if the earliest ride in the dataset predates that, you know you the dataset has a problem. Performing these kinds of basic sanity checks on the data is critical and something you should always do when exploring a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-parallel",
   "metadata": {},
   "source": [
    "#### 3.1.3 What is the mean duration of all trips?\n",
    "\n",
    "Calculating this statistic will involve (1) selecting a column from the Pandas dataframe and (2) applying an aggregate function (e.g., a mean) to a column of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-religious",
   "metadata": {},
   "source": [
    "#### 3.1.4 Do men or women take longer trips on average?\n",
    "\n",
    "The goal of this question is to give you experience with the groupby function in Pandas, as well as how to combine groupby with an aggregation operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-climb",
   "metadata": {},
   "source": [
    "#### 3.1.5 Birth Year Sanity Check\n",
    "\n",
    "We know anecdotally that the birth year column (`BIRTH YEAR`) has several missing values. How many rows are missing a birth year? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-entity",
   "metadata": {},
   "source": [
    "#### 3.1.6 Do women under 40 or women 40+ take longer trips on average?\n",
    "\n",
    "This will require grouping by more attributes and then applying an aggregate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-overall",
   "metadata": {},
   "source": [
    "### 3.2.1 Basic Plotting and Visualization\n",
    "\n",
    "Now you will get some practice plotting data\n",
    "\n",
    "#### 3.2.1 Set a time index in the data frame\n",
    "Recall the example above and set one of the columns in the data frame to be a datetime index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-ultimate",
   "metadata": {},
   "source": [
    "#### 3.1.2 Plot the total trip duration by day of the week\n",
    "\n",
    "Visualize whether people spend more time riding Divvy bikes on particular days of the week. While there are a number of ways to perform this operation, you may find the `resample` function in Pandas useful. Remember to label your plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-beads",
   "metadata": {},
   "source": [
    "### 3.3 Data Exploration on Your Own\n",
    "\n",
    "Pick a question or hypothesis related to the Divvy bike share data, justify **why** you picked that question (i.e., why it might be an interesting question to some audience, such as city officials), and present a simple analysis. \n",
    "\n",
    "Some example questions might include:\n",
    "* Adjusting for seasons, is ridership increasing? (You could use conditional selection on dates or months.)\n",
    "* Are rides getting longer? (on average? max?)\n",
    "* Do ride characteristics differ by user type?\n",
    "* Are certain trip routes (e.g. pairs of start and end stations) more popular than others? Does this change during peak and non-peak \"rush\" hours (defined loosely)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (add cells below as needed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
